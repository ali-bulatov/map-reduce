{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEQUENTIAL MAP REDUCE RESULTS: \n",
      " \n",
      "Most Common Words Found in US Craft Beer Names:\n",
      "('ale', 368400)\n",
      "('ipa', 200400)\n",
      "('pale', 144000)\n",
      "('lager', 65400)\n",
      "('amber', 45000)\n",
      "('stout', 43800)\n",
      "('blonde', 38400)\n",
      "('wheat', 37200)\n",
      "('red', 37200)\n",
      "('brown', 37200)\n",
      "\n",
      "\n",
      "CPU times: user 33.6 s, sys: 378 ms, total: 34 s\n",
      "Wall time: 44.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#calculate the execution time\n",
    "\n",
    "#import pandas to read the file\n",
    "import pandas as pd\n",
    "#import regular expressions\n",
    "import re\n",
    "#import conuter to count the amount of times word appears in text\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "\n",
    "#words that should be discarded from the word counting\n",
    "STOP_WORDS = set([\n",
    "            'a', 'an', 'and', 'are', 'as', 'be', 'by', 'for', 'if', 'in', \n",
    "            'is', 'it', 'of', 'or', 'py', 'rst', 'that', 'the', 'to', 'with',\n",
    "            ])\n",
    "\n",
    "#read the csv file\n",
    "beer_data = pd.read_csv (r'beers.csv')\n",
    "#pick the column with beer names\n",
    "beer_names = pd.DataFrame(beer_data, columns= ['name'])\n",
    "#cast the dataframe to list\n",
    "lst_beer_names = beer_names.values.tolist()\n",
    "#multiply the data by 100 to better see the improvements of parallelization\n",
    "large_lst_beer_names = lst_beer_names*600\n",
    "\n",
    "#clean the data\n",
    "def clean_word(word):\n",
    "    return re.sub(r'[^\\w\\s]','',word).lower()\n",
    "#filter the data\n",
    "def word_not_in_stopwords(word):\n",
    "    return word not in STOP_WORDS and word and word.isalpha()  \n",
    "\n",
    "#get a text split it into tokens clean them, filter them, count them\n",
    "def mapper(text):\n",
    "    string = ''.join(text)\n",
    "    tokens_in_text = string.split()\n",
    "    tokens_in_text = map(clean_word, tokens_in_text)\n",
    "    tokens_in_text = filter(word_not_in_stopwords, tokens_in_text)\n",
    "    return Counter(tokens_in_text)\n",
    "#get 2 counters and merge them\n",
    "def reducer(cnt1, cnt2):\n",
    "    cnt1.update(cnt2)\n",
    "    return cnt1\n",
    "#get a chunk a do a mapreduce on it\n",
    "def chunk_mapper(chunk):\n",
    "    mapped = map(mapper, chunk)\n",
    "    reduced = reduce(reducer, mapped)\n",
    "    return reduced\n",
    "\n",
    "#yield successive n-sized chunks from list\n",
    "def chunkify(lst, n):\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "#split data into 36 chunks\n",
    "data_chunks = chunkify(large_lst_beer_names, 36)\n",
    "#mapping\n",
    "mapped = map(chunk_mapper, data_chunks)\n",
    "#reduce\n",
    "reduced = reduce(reducer, mapped)\n",
    "#print the top 10 words found in the craft beer names\n",
    "print(\"SEQUENTIAL MAP REDUCE RESULTS: \\n \\nMost Common Words Found in US Craft Beer Names:\")\n",
    "for name in reduced.most_common(10):\n",
    "    print(name)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
